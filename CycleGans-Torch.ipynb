{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb55339e",
   "metadata": {},
   "source": [
    "# **Torch Implmentation of CycleGANs**\n",
    "\n",
    "### **What is CycleGANs?**\n",
    "CycleGANs solves the computer vision problem of translating the style of one image (or sets of images) to the another using artificial neural networks, convolutional layers, and deep learning methods such as gradient descent, to optimize the output for a particular style.\n",
    "\n",
    "Implementation adopted from and based on these sources:\n",
    "1. [**CycleGANs Paper**](./data/1703.10593.pdf)\n",
    "2. [**GitHub Repository of CycleGANs Paper**](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)\n",
    "3. [**Code based on this Torch Implementation**](https://github.com/yunjey/mnist-svhn-transfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b59629-2c6a-4827-a08a-04f07625b9df",
   "metadata": {},
   "source": [
    "### Package Requirements\n",
    "\n",
    "- Python version 3.x\n",
    "- Torch version 1.9\n",
    "- Torchvision version 0.10\n",
    "- imageio version 2.9.0\n",
    "- numpy version 1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82f49c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import pickle\n",
    "import imageio\n",
    "import numpy as np\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c784e0-705d-4a5f-ae51-6816e2b8bdaf",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "- svhn: [The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers/)\n",
    "- mnist: [Modified National Institute of Standards and Technology database](https://en.wikipedia.org/wiki/MNIST_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c837d26a-c84b-4996-8c70-b6c853e3055e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./svhn/train_32x32.mat\n"
     ]
    }
   ],
   "source": [
    "svhn_path='./svhn'\n",
    "mnist_path='./mnist'\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(32),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "svhn = datasets.SVHN(root=svhn_path, \n",
    "                     download=True, \n",
    "                     transform=transform)\n",
    "\n",
    "mnist = datasets.MNIST(root=mnist_path, \n",
    "                       download=True, \n",
    "                       transform=transform)\n",
    "    \n",
    "svhn_loader = torch.utils.data.DataLoader(dataset=svhn,\n",
    "                                          batch_size=64,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=2)\n",
    "\n",
    "mnist_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                           batch_size=64,\n",
    "                                               \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7f1918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27aa1c-a7c2-48c8-9442-b11be25653ef",
   "metadata": {},
   "source": [
    "- Conv2d and ConvTranspose2d Layers with BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b1216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    layers=[]\n",
    "    layers.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv(c_in, c_out, k_size, stride=2, pad=1, bn=True):\n",
    "    layers=[]\n",
    "    layers.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=False))\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(c_out))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ebbfb4-b3d4-42ff-9573-8d123f255c8e",
   "metadata": {},
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "be600351",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G12(nn.Module):\n",
    "    def __init__(self, conv_dim=64):\n",
    "        super(G12, self).__init__()\n",
    "        self.conv1 = conv(1, conv_dim, 4)\n",
    "        self.conv2 = conv(conv_dim, conv_dim * 2, 4)\n",
    "        \n",
    "        self.conv3 = conv(conv_dim * 2, conv_dim * 2, 3, 1, 1)\n",
    "        self.conv4 = conv(conv_dim * 2, conv_dim * 2, 3, 1, 1)\n",
    "        \n",
    "        self.deconv1 = deconv(conv_dim * 2, conv_dim, 4)\n",
    "        self.deconv2 = deconv(conv_dim, 3, 4, bn=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.conv1(x), 0.05)\n",
    "        out = F.leaky_relu(self.conv2(out), 0.05)\n",
    "        \n",
    "        out = F.leaky_relu(self.conv3(out), 0.05)\n",
    "        out = F.leaky_relu(self.conv4(out), 0.05)\n",
    "        \n",
    "        out = F.leaky_relu(self.deconv1(out), 0.05)\n",
    "        out = torch.tanh(self.deconv2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0a3c05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class G21(nn.Module):\n",
    "    def __init__(self, conv_dim=64):\n",
    "        super(G21, self).__init__()\n",
    "        self.conv1 = conv(3, conv_dim, 4)\n",
    "        self.conv2 = conv(conv_dim, conv_dim * 2, 4)\n",
    "        \n",
    "        self.conv3 = conv(conv_dim * 2, conv_dim * 2, 3, 1, 1)\n",
    "        self.conv4 = conv(conv_dim * 2, conv_dim * 2, 3, 1, 1)\n",
    "        \n",
    "        self.deconv1 = deconv(conv_dim * 2, conv_dim, 4)\n",
    "        self.deconv2 = deconv(conv_dim, 1, 4, bn=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.conv1(x), 0.05)\n",
    "        out = F.leaky_relu(self.conv2(out), 0.05)\n",
    "    \n",
    "        out = F.leaky_relu(self.conv3(out), 0.05)\n",
    "        out = F.leaky_relu(self.conv4(out), 0.05)\n",
    "    \n",
    "        out = F.leaky_relu(self.deconv1(out), 0.05)\n",
    "        out = torch.tanh(self.deconv2(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433ef07-891b-4a89-9645-857663059a2a",
   "metadata": {},
   "source": [
    "### Discriminators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4160b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D1(nn.Module):   \n",
    "    def __init__(self, conv_dim=64, use_labels=False):\n",
    "        super(D1, self).__init__()\n",
    "        self.conv1 = conv(1, conv_dim, 4, bn=False)\n",
    "        self.conv2 = conv(conv_dim, conv_dim * 2, 4)\n",
    "        self.conv3 = conv(conv_dim * 2, conv_dim * 4, 4)\n",
    "        n_out = 11 if use_labels else 1\n",
    "        self.fc = conv(conv_dim * 4, n_out, 4, 1, 0, False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.conv1(x), 0.05)\n",
    "        out = F.leaky_relu(self.conv2(out), 0.05)\n",
    "        out = F.leaky_relu(self.conv3(out), 0.05)\n",
    "        out = self.fc(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db7f4bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D2(nn.Module):\n",
    "    def __init__(self, conv_dim=64, use_labels=False):\n",
    "        super(D2, self).__init__()\n",
    "        self.conv1 = conv(3, conv_dim, 4, bn=False)\n",
    "        self.conv2 = conv(conv_dim, conv_dim * 2, 4)\n",
    "        self.conv3 = conv(conv_dim * 2, conv_dim * 4, 4)\n",
    "        n_out = 11 if use_labels else 1\n",
    "        self.fc = conv(conv_dim * 4, n_out, 4, 1, 0, False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.leaky_relu(self.conv1(x), 0.05)\n",
    "        out = F.leaky_relu(self.conv2(out), 0.05)\n",
    "        out = F.leaky_relu(self.conv3(out), 0.05)\n",
    "        out = self.fc(out).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bddf6f-5a04-487a-ba51-8c08de316d0b",
   "metadata": {},
   "source": [
    "### CycleGans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eed255b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGans(object):\n",
    "    def __init__(self, s, m):\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.use_reconst_loss = True\n",
    "        self.use_labels = True\n",
    "        self.num_classes = 10\n",
    "        self.beta1 = 0.5\n",
    "        self.beta2 = 0.999\n",
    "        self.g_conv_dim = 64\n",
    "        self.d_conv_dim = 64\n",
    "        self.train_iters = 500000\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.0002\n",
    "        self.log_step = 1000\n",
    "        self.sample_step = 5000\n",
    "        self.sample_path = './samples' \n",
    "        self.model_path = './models'\n",
    "        self.build_model()\n",
    "    \n",
    "    def build_model(self):\n",
    "        self.g12 = G12(conv_dim=self.g_conv_dim)\n",
    "        self.g21 = G21(conv_dim=self.g_conv_dim)\n",
    "        self.d1 = D1(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n",
    "        self.d2 = D2(conv_dim=self.d_conv_dim, use_labels=self.use_labels)\n",
    "        \n",
    "        g_params = list(self.g12.parameters()) + list(self.g21.parameters())\n",
    "        d_params = list(self.d1.parameters()) + list(self.d2.parameters())\n",
    "        \n",
    "        self.g_optimizer = optim.Adam(g_params, self.lr, [self.beta1, self.beta2])\n",
    "        self.d_optimizer = optim.Adam(g_params, self.lr, [self.beta1, self.beta2])\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.g12.cuda()\n",
    "            self.g21.cuda()\n",
    "            self.d1.cuda()\n",
    "            self.d2.cuda()\n",
    "            \n",
    "    def merge_images(self, sources, targets, k=10):\n",
    "        _, _, h, w = sources.shape\n",
    "        row = int(np.sqrt(self.batch_size))\n",
    "        merged = np.zeros([3, row * h, row * w * 2])\n",
    "        for idx, (s, t) in enumerate(zip(sources, targets)):\n",
    "            i = idx // row\n",
    "            j = idx % row\n",
    "            merged[:, i*h:(i + 1) * h, (j * 2) * h: (j * 2 + 1) * h] = s\n",
    "            merged[:, i*h:(i + 1) * h, (j * 2 + 1) * h:(j * 2 + 2) * h] = t\n",
    "        return merged.transpose(1, 2, 0)\n",
    "    \n",
    "    def to_var(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "        return Variable(x)\n",
    "    \n",
    "    def to_data(self, x):\n",
    "        if torch.cuda.is_available():\n",
    "            x = x.cpu()\n",
    "        return torch.from_numpy(x.data.numpy())\n",
    "    \n",
    "    def reset_grad(self):\n",
    "        self.g_optimizer.zero_grad()\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "    def train(self):\n",
    "        svhn_iter = iter(self.s)\n",
    "        mnist_iter = iter(self.m)\n",
    "        iter_per_epoch = min(len(svhn_iter), len(mnist_iter))\n",
    "        \n",
    "        fixed_svhn = self.to_var(svhn_iter.next()[0])\n",
    "        fixed_mnist = self.to_var(mnist_iter.next()[0])\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        for step in range(self.train_iters + 1):\n",
    "            if (step + 1) % iter_per_epoch == 0:\n",
    "                mnist_iter = iter(self.m)\n",
    "                svhn_iter = iter(self.s)\n",
    "                \n",
    "            svhn, s_labels = svhn_iter.next()\n",
    "            svhn, s_labels = self.to_var(svhn), self.to_var(s_labels).long().squeeze()\n",
    "            mnist, m_labels = mnist_iter.next()\n",
    "            mnist, m_labels = self.to_var(mnist), self.to_var(m_labels)\n",
    "            \n",
    "            if self.use_labels:\n",
    "                mnist_fake_labels = self.to_var(\n",
    "                    torch.Tensor([self.num_classes] * svhn.size(0)).long())\n",
    "                svhn_fake_labels = self.to_var(\n",
    "                    torch.Tensor([self.num_classes] * mnist.size(0)).long())\n",
    "                \n",
    "            self.reset_grad()\n",
    "            out = self.d1(mnist)\n",
    "            if self.use_labels:\n",
    "                d1_loss = criterion(out, m_labels)\n",
    "            else:\n",
    "                d1_loss = torch.mean((out - 1) ** 2)\n",
    "                \n",
    "            out = self.d2(svhn)\n",
    "            if self.use_labels:\n",
    "                d2_loss = criterion(out, s_labels)\n",
    "            else:\n",
    "                d2_loss = torch.mean((out - 1) ** 2)\n",
    "                \n",
    "            d_mnist_loss = d1_loss\n",
    "            d_svhn_loss = d2_loss\n",
    "            d_real_loss = d1_loss + d2_loss\n",
    "            d_real_loss.backward()\n",
    "            self.d_optimizer.step()\n",
    "            \n",
    "            self.reset_grad()\n",
    "            fake_svhn = self.g12(mnist)\n",
    "            out = self.d2(fake_svhn)\n",
    "            if self.use_labels:\n",
    "                d2_loss = criterion(out, svhn_fake_labels)\n",
    "            else:\n",
    "                d2_loss = torch.mean(out**2)\n",
    "            fake_mnist = self.g21(svhn)\n",
    "            out = self.d1(fake_mnist)\n",
    "            if self.use_labels:\n",
    "                d1_loss = criterion(out, mnist_fake_labels)\n",
    "            else:\n",
    "                d1_loss = torch.mean(out**2)\n",
    "            d_fake_loss = d1_loss + d2_loss\n",
    "            d_fake_loss.backward()\n",
    "            self.d_optimizer.step()\n",
    "            \n",
    "            self.reset_grad()\n",
    "            fake_svhn =self.g12(mnist)\n",
    "            out = self.d2(fake_svhn)\n",
    "            reconst_mnist = self.g21(fake_svhn)\n",
    "            if self.use_labels:\n",
    "                g_loss = criterion(out, m_labels)\n",
    "            else:\n",
    "                g_loss = torch.mean((out - 1) ** 2)\n",
    "                \n",
    "            if self.use_reconst_loss:\n",
    "                g_loss += torch.mean((mnist - reconst_mnist) ** 2)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            self.g_optimizer.step()\n",
    "            \n",
    "            self.reset_grad()\n",
    "            fake_mnist = self.g21(svhn)\n",
    "            out = self.d1(fake_mnist)\n",
    "            reconst_svhn = self.g12(fake_mnist)\n",
    "            if self.use_labels:\n",
    "                g_loss = criterion(out, s_labels)\n",
    "            else:\n",
    "                g_loss = torch.mean((out - 1) ** 2)\n",
    "            \n",
    "            if self.use_reconst_loss:\n",
    "                g_loss += torch.mean((svhn - reconst_svhn) ** 2)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            self.g_optimizer.step()\n",
    "            \n",
    "            if (step + 1) % self.log_step == 0:\n",
    "                print('Step [%d/%d], d_real_loss: %.4f, d_fake_loss: %.4f, g_loss; %.4f' % (step+1,\n",
    "                                                                                            self.train_iters,\n",
    "                                                                                            d_real_loss.data.item(),\n",
    "                                                                                            d_fake_loss.data.item(),\n",
    "                                                                                            g_loss.data.item()))\n",
    "                \n",
    "            if (step + 1) % self.sample_step == 0:\n",
    "                fake_svhn = self.g12(fixed_mnist)\n",
    "                fake_mnist = self.g21(fixed_svhn)\n",
    "                \n",
    "                mnist, fake_mnist = self.to_data(fixed_mnist), self.to_data(fake_mnist)\n",
    "                svhn, fake_svhn = self.to_data(fixed_svhn), self.to_data(fake_svhn)\n",
    "                \n",
    "                merged = self.merge_images(mnist, fake_svhn)\n",
    "                path = os.path.join(self.sample_path, 'sample-%d-m-s.png' %(step + 1))\n",
    "                imageio.imwrite(path, (merged[:, :, 0]*255).astype(np.uint8))\n",
    "                print('saved %s' %path)\n",
    "                \n",
    "                merged = self.merge_images(svhn, fake_mnist)\n",
    "                path = os.path.join(self.sample_path, 'sample-%d-s-m.png' %(step + 1))\n",
    "                imageio.imwrite(path, (merged[:, :, 0]*255).astype(np.uint8))\n",
    "                print('saved %s' %path)\n",
    "                \n",
    "            if (step + 1) % 5000 == 0:\n",
    "                \n",
    "                g12_path = os.join(self.model_path, 'g12-%d.pkl' % (step+1))\n",
    "                g21_path = os.join(self.model_path, 'g21-%d.pkl' %(step + 1))\n",
    "                d1_path = os.path.join(self.model_path, 'd1-%d.pkl' %(step + 1))\n",
    "                d2_path = os.path.join(self.model_path, 'd2-%d.pkl' %(step + 1))\n",
    "                \n",
    "                torch.save(self.g12.state_dict(), g12_path)\n",
    "                torch.save(self.g21.state_dict(), g21_path)\n",
    "                torch.save(self.d1.state_dict(), d1_path)\n",
    "                torch.save(self.d2.state_dict(), d2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c816218f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [10/50], d_real_loss: 4.8725, d_fake_loss: 2.2086, g_loss; 3.1746\n",
      "Step [20/50], d_real_loss: 4.8294, d_fake_loss: 1.6392, g_loss; 3.1834\n",
      "Step [30/50], d_real_loss: 4.9983, d_fake_loss: 1.5757, g_loss; 3.1731\n",
      "Step [40/50], d_real_loss: 5.1253, d_fake_loss: 1.4935, g_loss; 3.1146\n",
      "Step [50/50], d_real_loss: 4.8509, d_fake_loss: 1.4044, g_loss; 3.1127\n",
      "saved ./samples/sample-50-m-s.png\n",
      "saved ./samples/sample-50-s-m.png\n"
     ]
    }
   ],
   "source": [
    "gans = CycleGans(svhn_loader, mnist_loader)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('./models'):\n",
    "    os.makedirs('./models')\n",
    "if not os.path.exists('./samples'):\n",
    "    os.makedirs('./samples')\n",
    "    \n",
    "gans.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ccb28-77e4-4a3d-800a-044a38b653d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
